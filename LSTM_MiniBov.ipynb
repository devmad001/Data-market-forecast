{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cbef66f",
   "metadata": {},
   "source": [
    "# Projeto - Previsão da Cotação do Mini Indice BOVESP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36207d",
   "metadata": {},
   "source": [
    "Projeto de Previsão de Preços de Instrumentos Financeiros listados em bolsa com Redes Neurais Tensorflow\n",
    "\n",
    "Este projeto tem como objetivo desenvolver uma rede neural para prever os preços futuros do ativos financeiros relativos ao minicontrato (contrato fracionário) do indice da bolsa de valores de Sâo Paulo (Mini-IBOV), proporcionando insights valiosos para tomadas de decisão no mercado. Utilizaremos a linguagem de programação Python e bibliotecas poderosas de aprendizado de máquina para construir e treinar nosso modelo preditivo.\n",
    "\n",
    "Ao final deste projeto, esperamos não apenas fornecer uma ferramenta funcional de previsão de preços, mas também promover uma compreensão mais profunda sobre o uso de redes neurais em finanças e suas aplicações práticas.\n",
    "\n",
    "Sinta-se à vontade para explorar o código-fonte e os resultados no repositório associado. Contribuições e feedback são sempre bem-vindos!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db247be",
   "metadata": {},
   "source": [
    "## Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc34e437",
   "metadata": {},
   "source": [
    "O objetivo principal deste projeto é criar uma ferramenta eficaz que possa analisar dados históricos de preços e, com base nessa análise, fazer previsões confiáveis sobre o comportamento futuro do ativo financeiro em questão. Ao empregar técnicas avançadas de aprendizado de máquina, buscamos proporcionar aos investidores uma vantagem estratégica ao antecipar tendências de mercado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9387fe57",
   "metadata": {},
   "source": [
    "## Tecnologias Utilizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff5b6f",
   "metadata": {},
   "source": [
    "- Python: Linguagem de programação versátil e poderosa.\n",
    "- TensorFlow/Keras: Bibliotecas líderes para desenvolvimento de redes neurais.\n",
    "- Pandas: Manipulação e análise de dados.\n",
    "- Matplotlib/Seaborn: Visualização de dados para uma compreensão mais clara.\n",
    "- Jupyter Notebooks: Ambiente interativo para desenvolvimento e experimentação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00133dff",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Etapas do Projeto\n",
    "1. **Projeto - Introdução:** Apresentação do projeto, Objetivos e Conclusão.\n",
    "2. **Bibliotecas e Dados:** Carregar as bibliotecas que serão utilizadas no projeto e carregar os dados históricos do ativo financeiro em consideração.\n",
    "3. **Transformação dos recursos e Tratamento dos Dados:** Limpar e organizar os dados e enriquece-los para prepará-los para a modelagem.\n",
    "4. **Pré-processamento:** Limpar e organizar os dados para prepará-los para a modelagem.\n",
    "5. **Desenvolvimento do Modelo e Treino:** Construir e treinar a rede neural para aprendizado e previsão.\n",
    "6. **Avaliação e Ajuste:** Avaliar o desempenho do modelo e ajustar parâmetros conforme necessário.\n",
    "7. **Previsões Futuras:** Utilizar o modelo treinado para realizar previsões de preços futuros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28ffd31",
   "metadata": {},
   "source": [
    "# Bibliotecas e Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478593d1",
   "metadata": {},
   "source": [
    "Importar todas as bibliotecas que serão necessárias para a realização integral do projeto e carregamento nossos dados brutos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba0579",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d4b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b39e594",
   "metadata": {},
   "source": [
    "### Definir os parametros de algumas biblitecas.\n",
    "Iremos definir as sementes de aleatóriedades para que nosso projeto possa ser testo e garantir que os resultados sejam reproduzidos para fim de avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e927a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "rn.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c610f265",
   "metadata": {},
   "source": [
    "### Vamos verificar se a biblioteca Tensorflow usará a GPU\n",
    "Teste simples para garantirmos que treinamento seja otimizado utilizando a GPU para processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f55bcd12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595fe72b",
   "metadata": {},
   "source": [
    "## Dados\n",
    "Os conjuntos de dados utilizados neste projeto foram disponibilizados pela B3 por meio de uma corretora parceira. Realizamos um processo de extração e organização preliminares, alinhando os dados de acordo com os vencimentos dos contratos de liquidação. Este procedimento foi essencial para lidar com a complexidade dos dados brutos previamente obtidos, proporcionando uma base sólida e estruturada para a análise e modelagem subsequente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5240bcaa",
   "metadata": {},
   "source": [
    "### WINN\n",
    "Dados tabulares referente aos todos contratos anteriores aos ultimos dois contratos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "597e75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_winn = r'C:\\Users\\adria\\1Python\\Meu_novo_projeto\\WIN_N_1K\\WIN_N_1k.csv'\n",
    "winn = pd.read_csv(path_winn, index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a5996d",
   "metadata": {},
   "source": [
    "### WING\n",
    "Ultimo contrato com vencimento fechado. Neste caso vamos usar o WING23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fc4cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_wing = r'C:\\Users\\adria\\1Python\\Meu_novo_projeto\\WING23\\WING23.csv'\n",
    "wing = pd.read_csv(path_wing, index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22d40c",
   "metadata": {},
   "source": [
    "### WINJ\n",
    "Atual contrato com vencimento aberto. Neste caso vamos usar o WINJ23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16c0a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_winj = r'C:\\Users\\adria\\1Python\\Meu_novo_projeto\\WINJ23\\WINJ23.csv'\n",
    "winj = pd.read_csv(path_winj, index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0e030d",
   "metadata": {},
   "source": [
    "# Transformação dos Recursos e Tratamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251fcfa2",
   "metadata": {},
   "source": [
    "Iniciaremos a transformação dos dados, adaptando-os para um formato compatível como recursos em nosso modelo. Este processo abrange etapas cruciais de enriquecimento, limpeza e normalização.\n",
    "\n",
    "Realizamos o mesmo conjunto de procedimentos nos três dataframes, atribuindo a cada um deles uma função específica como conjunto de treinamento, validação e teste. Essa abordagem garante consistência e prepara os dados de maneira uniforme para otimizar o desempenho do modelo durante as fases subsequentes de treinamento e avaliação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f09ba68",
   "metadata": {},
   "source": [
    "## Enriquecimento de dados\n",
    "Para aprimorar a base de dados, introduziremos dois novos recursos (colunas) significativos.\n",
    "A inclusão desses recursos enriquecedores visa aprimorar a capacidade do modelo em captar sinais mais precisos sobre a direção do mercado, contribuindo para uma análise mais robusta e eficaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6054348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Coluna 'hl':\n",
    "#   - Representa a média aritmética entre o valor máximo do período, o valor mínimo e duas vezes o valor de fechamento.\n",
    "#   - A fórmula utilizada é: ('high' + 'low' + 2 * 'close') / 4\n",
    "#2. Coluna 'mvhl':\n",
    "#   - Corresponde à média móvel de dois períodos da coluna 'hl'.\n",
    "#   - Essa média móvel ajuda a reduzir o ruído nos preços, oferecendo uma visão mais clara das tendências do mercado.\n",
    "\n",
    "winn['hl'] = (winn['high'] + winn['low'] + winn['close'] + winn['close']) / 4\n",
    "lag = 2\n",
    "winn['mvhl'] = winn['hl'].rolling(lag).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02b6b8c",
   "metadata": {},
   "source": [
    "### Limpeza de dados\n",
    "Vamos retirar os dados que não serão usados para nossa analise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14a8c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "winn = winn.drop(['open', 'tick_volume','real_volume'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed4cd937",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = winn.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95c230a",
   "metadata": {},
   "source": [
    "Iremos criar uma base sem qualquer dado faltante com o nome 'train'. Essa nova base será utilizada para treinamento de nosso modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06aed93",
   "metadata": {},
   "source": [
    "### Escala dos dados\n",
    "Todos os dados, já no formato numérico float, passarão por uma etapa crucial de ajuste de escala. \n",
    "Essa transformação será realizada utilizando o MinMaxScaler da biblioteca scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84a9b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "train = scaler.fit_transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bec51c",
   "metadata": {},
   "source": [
    "## Validacao\n",
    "Série temporal referente à serie historica recente contrato wing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6458c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "wing['hl'] = (wing['high'] + wing['low'] + wing['close'] + wing['close']) / 4\n",
    "wing['mvhl'] = wing['hl'].rolling(lag).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "569f77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wing = wing.drop(['open', 'tick_volume','real_volume'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74a06531",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = wing.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf199330",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = scaler.transform(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466db068",
   "metadata": {},
   "source": [
    "## Teste\n",
    "Série temporal referente à serie historica atual contrato winj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db02f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "winj['hl'] = (winj['high'] + winj['low'] + winj['close'] + winj['close']) / 4\n",
    "winj['mvhl'] = winj['hl'].rolling(lag).mean()\n",
    "winj = winj.drop(['open', 'tick_volume','real_volume'], axis=1)\n",
    "test = winj.dropna()\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d8ab91",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45a30e3",
   "metadata": {},
   "source": [
    "Para realizar o pré-processamento dos dados, optaremos pelo modelo de janelas em sequência. Essa escolha se fundamenta na limitada quantidade de amostras disponíveis tanto para os conjuntos de teste quanto de treinamento. O uso desse modelo permite uma abordagem eficaz, considerando a escassez de dados, ao organizar as informações em janelas sequenciais, proporcionando uma representação mais abrangente das relações temporais presentes nos conjuntos de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a31c75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "window_size = 32\n",
    "num_inputs  = train.shape[1]\n",
    "num_targets = 3\n",
    "stride = 3\n",
    "sampling_rate=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3123dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_sequence(data, window_size, num_inputs, num_targets, stride, batch_size, sampling_rate=1):\n",
    "\n",
    "    num_examples = (len(data) - window_size) // stride\n",
    "    num_batches = num_examples // batch_size\n",
    "    inputs = np.zeros((num_examples, window_size, num_inputs))\n",
    "    targets = np.zeros((num_examples, num_targets))\n",
    "    \n",
    "    for i in range(num_examples):\n",
    "        idx = i * stride\n",
    "        inputs[i] = data[idx : idx+window_size : sampling_rate, :num_inputs]\n",
    "        targets[i] = data[idx+window_size : idx+window_size+num_targets, -1]\n",
    "    \n",
    "    batch_inputs = np.zeros((batch_size, window_size, num_inputs))\n",
    "    batch_targets = np.zeros((batch_size, num_targets))\n",
    "    while True:\n",
    "        for b in range(num_batches):\n",
    "            batch_start = b * batch_size\n",
    "            batch_inputs = inputs[batch_start:batch_start+batch_size]\n",
    "            batch_targets = targets[batch_start:batch_start+batch_size]\n",
    "            yield batch_inputs, batch_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3807bde",
   "metadata": {},
   "source": [
    " def sliding_window_sequence(data, window_size, num_inputs, num_targets, stride, batch_size, sampling_rate=1):\n",
    "    # Calcula o número total de exemplos que podem ser gerados usando a janela de tamanho fixo\n",
    "    num_examples = (len(data) - window_size) // stride\n",
    "    \n",
    "    # Calcula o número de lotes (batches) que podem ser gerados\n",
    "    num_batches = num_examples // batch_size\n",
    "    \n",
    "    # Cria matrizes numpy para armazenar inputs e targets\n",
    "    inputs = np.zeros((num_examples, window_size, num_inputs))\n",
    "    targets = np.zeros((num_examples, num_targets))\n",
    "    \n",
    "    # Loop através de cada exemplo e armazena-os nas matrizes inputs e targets\n",
    "    for i in range(num_examples):\n",
    "        idx = i * stride  # Calcula o índice inicial do exemplo atual\n",
    "        # Extrai a sequência de entrada do exemplo atual e armazena em inputs\n",
    "        inputs[i] = data[idx : idx+window_size : sampling_rate, :num_inputs]\n",
    "        # Extrai a sequência de targets do exemplo atual e armazena em targets\n",
    "        targets[i] = data[idx+window_size : idx+window_size+num_targets, -1]\n",
    "        #targets[i] = data[idx+window_size : idx+window_size+num_targets, :num_inputs] # todos os valores das linhas\n",
    "    \n",
    "    # Cria matrizes numpy para armazenar os inputs e targets de cada batch\n",
    "    batch_inputs = np.zeros((batch_size, window_size, num_inputs))\n",
    "    batch_targets = np.zeros((batch_size, num_targets))\n",
    "    \n",
    "    # Loop infinito para gerar batches de dados\n",
    "    while True:\n",
    "        # Loop através de cada batch\n",
    "        for b in range(num_batches):\n",
    "            batch_start = b * batch_size  # Calcula o índice inicial do batch atual\n",
    "            # Extrai os inputs do batch atual a partir da matriz inputs\n",
    "            batch_inputs = inputs[batch_start:batch_start+batch_size]\n",
    "            # Extrai os targets do batch atual a partir da matriz targets\n",
    "            batch_targets = targets[batch_start:batch_start+batch_size]\n",
    "            # Gera um batch de dados contendo inputs e targets\n",
    "            yield batch_inputs, batch_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "436765cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = sliding_window_sequence(train, window_size=window_size, num_inputs=num_inputs, num_targets=num_targets, stride=stride, batch_size=batch_size, sampling_rate=sampling_rate)\n",
    "valid_set = sliding_window_sequence(valid, window_size=window_size, num_inputs=num_inputs, num_targets=num_targets, stride=stride, batch_size=batch_size, sampling_rate=sampling_rate)\n",
    "test_set = sliding_window_sequence(test, window_size=window_size, num_inputs=num_inputs, num_targets=num_targets, stride=stride, batch_size=batch_size, sampling_rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a83a7",
   "metadata": {},
   "source": [
    "# Desenvolvimento do Modelo e Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd42d333",
   "metadata": {},
   "source": [
    "Para efetuar previsões, adotaremos uma Rede Neural Recorrente do tipo LSTM (Long Short-Term Memory). A escolha desta arquitetura se justifica pela sua capacidade notável em lidar com dependências temporais de longo prazo nos dados, tornando-a especialmente adequada para tarefas de previsão em séries temporais.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446c4705",
   "metadata": {},
   "source": [
    "Numero de recursos que serão utilizados para treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae7ae995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5bf13f",
   "metadata": {},
   "source": [
    "O código visa criar um modelo LSTM robusto para previsões, incorporando técnicas como regularização, dropout e a arquitetura TimeDistributed para melhorar a capacidade de generalização e prevenção de overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2e3407c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "781/781 [==============================] - 28s 24ms/step - loss: 0.0041 - mse: 0.0020 - val_loss: 0.0026 - val_mse: 6.8263e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/500\n",
      "781/781 [==============================] - 18s 23ms/step - loss: 0.0021 - mse: 6.4376e-04 - val_loss: 0.0022 - val_mse: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/500\n",
      "781/781 [==============================] - 18s 23ms/step - loss: 0.0018 - mse: 0.0010 - val_loss: 0.0017 - val_mse: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/500\n",
      "781/781 [==============================] - 18s 23ms/step - loss: 0.0015 - mse: 8.3386e-04 - val_loss: 0.0013 - val_mse: 6.3658e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/500\n",
      "781/781 [==============================] - 18s 23ms/step - loss: 0.0012 - mse: 6.2583e-04 - val_loss: 0.0010 - val_mse: 5.3069e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/500\n",
      "781/781 [==============================] - 18s 23ms/step - loss: 9.3328e-04 - mse: 4.5752e-04 - val_loss: 0.0011 - val_mse: 0.0010\n",
      "Epoch 7/500\n",
      "781/781 [==============================] - 18s 23ms/step - loss: 7.5387e-04 - mse: 3.4431e-04 - val_loss: 0.0012 - val_mse: 0.0014\n",
      "Epoch 8/500\n",
      "781/781 [==============================] - 18s 23ms/step - loss: 6.1819e-04 - mse: 2.8054e-04 - val_loss: 0.0012 - val_mse: 0.0015\n",
      "Epoch 9/500\n",
      "781/781 [==============================] - 18s 23ms/step - loss: 5.2502e-04 - mse: 2.6900e-04 - val_loss: 0.0010 - val_mse: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/500\n",
      "781/781 [==============================] - 18s 23ms/step - loss: 4.4609e-04 - mse: 2.5422e-04 - val_loss: 7.1665e-04 - val_mse: 8.5763e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/500\n",
      "781/781 [==============================] - 18s 23ms/step - loss: 3.7477e-04 - mse: 2.2215e-04 - val_loss: 4.2331e-04 - val_mse: 3.6469e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/500\n",
      "781/781 [==============================] - 18s 23ms/step - loss: 3.6195e-04 - mse: 2.7752e-04 - val_loss: 4.2031e-04 - val_mse: 4.2783e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/500\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 3.2174e-04 - mse: 2.5739e-04 - val_loss: 2.4177e-04 - val_mse: 1.2376e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/500\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 2.6550e-04 - mse: 1.9424e-04 - val_loss: 2.2507e-04 - val_mse: 1.3548e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/500\n",
      "781/781 [==============================] - 18s 23ms/step - loss: 2.4104e-04 - mse: 1.8752e-04 - val_loss: 3.1381e-04 - val_mse: 3.5128e-04\n",
      "Epoch 16/500\n",
      "781/781 [==============================] - 18s 23ms/step - loss: 2.2372e-04 - mse: 1.8756e-04 - val_loss: 4.1534e-04 - val_mse: 5.8484e-04\n",
      "Epoch 17/500\n",
      "781/781 [==============================] - 18s 24ms/step - loss: 2.0998e-04 - mse: 1.8757e-04 - val_loss: 4.8697e-04 - val_mse: 7.5257e-04\n",
      "Epoch 18/500\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 1.9236e-04 - mse: 1.7464e-04 - val_loss: 3.7693e-04 - val_mse: 5.5296e-04\n",
      "Epoch 19/500\n",
      "781/781 [==============================] - 18s 24ms/step - loss: 1.7954e-04 - mse: 1.6788e-04 - val_loss: 3.6476e-04 - val_mse: 5.4605e-04\n",
      "Epoch 20/500\n",
      "781/781 [==============================] - 18s 23ms/step - loss: 1.6914e-04 - mse: 1.6318e-04 - val_loss: 2.5870e-04 - val_mse: 3.4896e-04\n",
      "Epoch 21/500\n",
      "781/781 [==============================] - 18s 23ms/step - loss: 1.5293e-04 - mse: 1.4478e-04 - val_loss: 1.5209e-04 - val_mse: 1.4917e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 1.5011e-04 - mse: 1.5132e-04 - val_loss: 1.2308e-04 - val_mse: 1.0250e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "781/781 [==============================] - 19s 23ms/step - loss: 1.4077e-04 - mse: 1.4308e-04 - val_loss: 9.5645e-05 - val_mse: 5.7544e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 1.2719e-04 - mse: 1.2502e-04 - val_loss: 1.1206e-04 - val_mse: 9.9155e-05\n",
      "Epoch 25/500\n",
      "781/781 [==============================] - 19s 24ms/step - loss: 1.3976e-04 - mse: 1.5815e-04 - val_loss: 1.0174e-04 - val_mse: 8.5708e-05\n",
      "Epoch 26/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 1.2051e-04 - mse: 1.2619e-04 - val_loss: 9.7047e-05 - val_mse: 8.2716e-05\n",
      "Epoch 27/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 1.1177e-04 - mse: 1.1504e-04 - val_loss: 8.3348e-05 - val_mse: 6.1440e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 1.2266e-04 - mse: 1.4270e-04 - val_loss: 8.1082e-05 - val_mse: 6.2045e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 1.0867e-04 - mse: 1.1939e-04 - val_loss: 7.0571e-05 - val_mse: 4.5492e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 1.0148e-04 - mse: 1.0959e-04 - val_loss: 1.0391e-04 - val_mse: 1.1647e-04\n",
      "Epoch 31/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 1.0700e-04 - mse: 1.2494e-04 - val_loss: 1.2447e-04 - val_mse: 1.6141e-04\n",
      "Epoch 32/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 1.0027e-04 - mse: 1.1507e-04 - val_loss: 1.7256e-04 - val_mse: 2.6085e-04\n",
      "Epoch 33/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 9.6844e-05 - mse: 1.1162e-04 - val_loss: 2.4399e-04 - val_mse: 4.0679e-04\n",
      "Epoch 34/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 9.6171e-05 - mse: 1.1337e-04 - val_loss: 2.7619e-04 - val_mse: 4.7405e-04\n",
      "Epoch 35/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 9.0831e-05 - mse: 1.0550e-04 - val_loss: 2.4898e-04 - val_mse: 4.2242e-04\n",
      "Epoch 36/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 8.7020e-05 - mse: 1.0059e-04 - val_loss: 1.9213e-04 - val_mse: 3.1154e-04\n",
      "Epoch 37/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 9.2308e-05 - mse: 1.1373e-04 - val_loss: 1.7338e-04 - val_mse: 2.7642e-04\n",
      "Epoch 38/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 8.7189e-05 - mse: 1.0554e-04 - val_loss: 1.1687e-04 - val_mse: 1.6543e-04\n",
      "Epoch 39/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 8.0191e-05 - mse: 9.3548e-05 - val_loss: 6.7854e-05 - val_mse: 6.9763e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 8.3732e-05 - mse: 1.0273e-04 - val_loss: 5.7632e-05 - val_mse: 5.1380e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 8.2415e-05 - mse: 1.0186e-04 - val_loss: 5.2637e-05 - val_mse: 4.3161e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 7.8980e-05 - mse: 9.6588e-05 - val_loss: 5.7448e-05 - val_mse: 5.4508e-05\n",
      "Epoch 43/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 7.7417e-05 - mse: 9.5061e-05 - val_loss: 5.7029e-05 - val_mse: 5.5230e-05\n",
      "Epoch 44/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 7.8209e-05 - mse: 9.8168e-05 - val_loss: 5.1023e-05 - val_mse: 4.4526e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 7.7204e-05 - mse: 9.7474e-05 - val_loss: 4.9282e-05 - val_mse: 4.2160e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 7.1482e-05 - mse: 8.7270e-05 - val_loss: 7.8234e-05 - val_mse: 1.0116e-04\n",
      "Epoch 47/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 7.3807e-05 - mse: 9.3251e-05 - val_loss: 1.1891e-04 - val_mse: 1.8357e-04\n",
      "Epoch 48/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 7.2513e-05 - mse: 9.1774e-05 - val_loss: 1.3426e-04 - val_mse: 2.1529e-04\n",
      "Epoch 49/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 7.1586e-05 - mse: 9.1012e-05 - val_loss: 1.4682e-04 - val_mse: 2.4145e-04\n",
      "Epoch 50/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 6.8410e-05 - mse: 8.5695e-05 - val_loss: 1.4215e-04 - val_mse: 2.3312e-04\n",
      "Epoch 51/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 6.9356e-05 - mse: 8.8646e-05 - val_loss: 1.3335e-04 - val_mse: 2.1658e-04\n",
      "Epoch 52/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 6.7812e-05 - mse: 8.6480e-05 - val_loss: 9.8228e-05 - val_mse: 1.4731e-04\n",
      "Epoch 53/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 6.6954e-05 - mse: 8.5692e-05 - val_loss: 7.4236e-05 - val_mse: 1.0039e-04\n",
      "Epoch 54/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 6.7520e-05 - mse: 8.7730e-05 - val_loss: 5.6278e-05 - val_mse: 6.5379e-05\n",
      "Epoch 55/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 6.4707e-05 - mse: 8.2887e-05 - val_loss: 4.0498e-05 - val_mse: 3.4734e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 6.2561e-05 - mse: 7.9416e-05 - val_loss: 4.3864e-05 - val_mse: 4.2445e-05\n",
      "Epoch 57/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 6.6321e-05 - mse: 8.7788e-05 - val_loss: 5.0404e-05 - val_mse: 5.6411e-05\n",
      "Epoch 58/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 6.5124e-05 - mse: 8.6074e-05 - val_loss: 5.0906e-05 - val_mse: 5.8058e-05\n",
      "Epoch 59/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 5.8733e-05 - mse: 7.3942e-05 - val_loss: 6.1057e-05 - val_mse: 7.9203e-05\n",
      "Epoch 60/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 6.3813e-05 - mse: 8.4921e-05 - val_loss: 5.6379e-05 - val_mse: 7.0521e-05\n",
      "Epoch 61/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 6.5169e-05 - mse: 8.8240e-05 - val_loss: 4.0275e-05 - val_mse: 3.8698e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 5.7058e-05 - mse: 7.2542e-05 - val_loss: 3.8699e-05 - val_mse: 3.5992e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 5.6731e-05 - mse: 7.2654e-05 - val_loss: 1.0226e-04 - val_mse: 1.6367e-04\n",
      "Epoch 64/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 6.5761e-05 - mse: 9.1438e-05 - val_loss: 1.5638e-04 - val_mse: 2.7220e-04\n",
      "Epoch 65/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 5.8634e-05 - mse: 7.7563e-05 - val_loss: 1.7323e-04 - val_mse: 3.0621e-04\n",
      "Epoch 66/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 5.1440e-05 - mse: 6.3711e-05 - val_loss: 3.1579e-04 - val_mse: 5.9192e-04\n",
      "Epoch 67/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 6.0730e-05 - mse: 8.3087e-05 - val_loss: 4.6431e-04 - val_mse: 8.8946e-04\n",
      "Epoch 68/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 6.1726e-05 - mse: 8.5527e-05 - val_loss: 3.1459e-04 - val_mse: 5.9041e-04\n",
      "Epoch 69/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 5.0915e-05 - mse: 6.4244e-05 - val_loss: 2.0393e-04 - val_mse: 3.6983e-04\n",
      "Epoch 70/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 5.6671e-05 - mse: 7.6442e-05 - val_loss: 2.5715e-04 - val_mse: 4.7691e-04\n",
      "Epoch 71/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 5.8174e-05 - mse: 7.9898e-05 - val_loss: 1.6419e-04 - val_mse: 2.9144e-04\n",
      "Epoch 72/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 5.1574e-05 - mse: 6.7068e-05 - val_loss: 1.0774e-04 - val_mse: 1.7915e-04\n",
      "Epoch 73/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 5.1221e-05 - mse: 6.6909e-05 - val_loss: 1.5200e-04 - val_mse: 2.6820e-04\n",
      "Epoch 74/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 5.9174e-05 - mse: 8.3377e-05 - val_loss: 1.6461e-04 - val_mse: 2.9378e-04\n",
      "Epoch 75/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 5.3261e-05 - mse: 7.1799e-05 - val_loss: 1.4138e-04 - val_mse: 2.4762e-04\n",
      "Epoch 76/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.8213e-05 - mse: 6.2094e-05 - val_loss: 3.1349e-04 - val_mse: 5.9212e-04\n",
      "Epoch 77/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 5.5949e-05 - mse: 7.8093e-05 - val_loss: 3.2878e-04 - val_mse: 6.2310e-04\n",
      "Epoch 78/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 5.2533e-05 - mse: 7.1547e-05 - val_loss: 2.2112e-04 - val_mse: 4.0811e-04\n",
      "Epoch 79/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.7315e-05 - mse: 6.1455e-05 - val_loss: 2.0826e-04 - val_mse: 3.8296e-04\n",
      "Epoch 80/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 5.3565e-05 - mse: 7.4473e-05 - val_loss: 2.0981e-04 - val_mse: 3.8646e-04\n",
      "Epoch 81/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 5.1966e-05 - mse: 7.1538e-05 - val_loss: 9.8074e-05 - val_mse: 1.6339e-04\n",
      "Epoch 82/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.5719e-05 - mse: 5.9318e-05 - val_loss: 5.9190e-05 - val_mse: 8.6260e-05\n",
      "Epoch 83/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 5.2384e-05 - mse: 7.3119e-05 - val_loss: 6.6405e-05 - val_mse: 1.0100e-04\n",
      "Epoch 84/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.9747e-05 - mse: 6.8083e-05 - val_loss: 3.8066e-05 - val_mse: 4.4663e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 4.5767e-05 - mse: 6.0432e-05 - val_loss: 4.1449e-05 - val_mse: 5.1901e-05\n",
      "Epoch 86/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 5.1426e-05 - mse: 7.2153e-05 - val_loss: 4.7024e-05 - val_mse: 6.3266e-05\n",
      "Epoch 87/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.7536e-05 - mse: 6.4574e-05 - val_loss: 5.2014e-05 - val_mse: 7.3447e-05\n",
      "Epoch 88/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.7149e-05 - mse: 6.4136e-05 - val_loss: 8.2853e-05 - val_mse: 1.3540e-04\n",
      "Epoch 89/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.9049e-05 - mse: 6.8251e-05 - val_loss: 9.5245e-05 - val_mse: 1.6038e-04\n",
      "Epoch 90/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.6252e-05 - mse: 6.2899e-05 - val_loss: 1.0550e-04 - val_mse: 1.8112e-04\n",
      "Epoch 91/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.5272e-05 - mse: 6.1252e-05 - val_loss: 1.3431e-04 - val_mse: 2.3903e-04\n",
      "Epoch 92/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.8627e-05 - mse: 6.8271e-05 - val_loss: 1.2748e-04 - val_mse: 2.2562e-04\n",
      "Epoch 93/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.6541e-05 - mse: 6.4313e-05 - val_loss: 8.2722e-05 - val_mse: 1.3644e-04\n",
      "Epoch 94/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.4098e-05 - mse: 5.9730e-05 - val_loss: 6.4285e-05 - val_mse: 1.0000e-04\n",
      "Epoch 95/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.6289e-05 - mse: 6.4435e-05 - val_loss: 4.5820e-05 - val_mse: 6.3395e-05\n",
      "Epoch 96/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.5537e-05 - mse: 6.3155e-05 - val_loss: 3.1846e-05 - val_mse: 3.5763e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.5204e-05 - mse: 6.2731e-05 - val_loss: 2.9763e-05 - val_mse: 3.1963e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 4.3711e-05 - mse: 6.0022e-05 - val_loss: 3.6976e-05 - val_mse: 4.6774e-05\n",
      "Epoch 99/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.4978e-05 - mse: 6.2837e-05 - val_loss: 4.3237e-05 - val_mse: 5.9523e-05\n",
      "Epoch 100/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.4582e-05 - mse: 6.2252e-05 - val_loss: 4.9351e-05 - val_mse: 7.2059e-05\n",
      "Epoch 101/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.2886e-05 - mse: 5.9106e-05 - val_loss: 5.7567e-05 - val_mse: 8.8788e-05\n",
      "Epoch 102/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.4006e-05 - mse: 6.1620e-05 - val_loss: 7.2890e-05 - val_mse: 1.1974e-04\n",
      "Epoch 103/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.3046e-05 - mse: 5.9908e-05 - val_loss: 6.9656e-05 - val_mse: 1.1342e-04\n",
      "Epoch 104/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.3695e-05 - mse: 6.1423e-05 - val_loss: 8.9690e-05 - val_mse: 1.5383e-04\n",
      "Epoch 105/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.2917e-05 - mse: 6.0092e-05 - val_loss: 7.6637e-05 - val_mse: 1.2789e-04\n",
      "Epoch 106/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.1697e-05 - mse: 5.7890e-05 - val_loss: 8.9608e-05 - val_mse: 1.5412e-04\n",
      "Epoch 107/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.2626e-05 - mse: 5.9970e-05 - val_loss: 8.8865e-05 - val_mse: 1.5281e-04\n",
      "Epoch 108/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.2248e-05 - mse: 5.9398e-05 - val_loss: 1.0775e-04 - val_mse: 1.9083e-04\n",
      "Epoch 109/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.2070e-05 - mse: 5.9265e-05 - val_loss: 1.0663e-04 - val_mse: 1.8883e-04\n",
      "Epoch 110/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.2375e-05 - mse: 6.0095e-05 - val_loss: 1.1639e-04 - val_mse: 2.0853e-04\n",
      "Epoch 111/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.0971e-05 - mse: 5.7443e-05 - val_loss: 1.1418e-04 - val_mse: 2.0425e-04\n",
      "Epoch 112/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.1342e-05 - mse: 5.8372e-05 - val_loss: 1.3634e-04 - val_mse: 2.4886e-04\n",
      "Epoch 113/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.1933e-05 - mse: 5.9751e-05 - val_loss: 1.1174e-04 - val_mse: 1.9979e-04\n",
      "Epoch 114/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.0303e-05 - mse: 5.6689e-05 - val_loss: 1.1509e-04 - val_mse: 2.0670e-04\n",
      "Epoch 115/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.1957e-05 - mse: 6.0170e-05 - val_loss: 8.9308e-05 - val_mse: 1.5520e-04\n",
      "Epoch 116/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.9333e-05 - mse: 5.5088e-05 - val_loss: 7.0671e-05 - val_mse: 1.1809e-04\n",
      "Epoch 117/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.1278e-05 - mse: 5.9174e-05 - val_loss: 6.1100e-05 - val_mse: 9.9081e-05\n",
      "Epoch 118/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.1719e-05 - mse: 6.0183e-05 - val_loss: 3.9310e-05 - val_mse: 5.5494e-05\n",
      "Epoch 119/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.6362e-05 - mse: 4.9640e-05 - val_loss: 3.3565e-05 - val_mse: 4.4234e-05\n",
      "Epoch 120/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.1608e-05 - mse: 6.0369e-05 - val_loss: 3.5565e-05 - val_mse: 4.8393e-05\n",
      "Epoch 121/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 4.1689e-05 - mse: 6.0638e-05 - val_loss: 2.6419e-05 - val_mse: 3.0094e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 3.5428e-05 - mse: 4.8267e-05 - val_loss: 2.7862e-05 - val_mse: 3.3197e-05\n",
      "Epoch 123/500\n",
      "781/781 [==============================] - 18s 22ms/step - loss: 4.1564e-05 - mse: 6.0742e-05 - val_loss: 3.3945e-05 - val_mse: 4.5488e-05\n",
      "Epoch 124/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 3.9414e-05 - mse: 5.6527e-05 - val_loss: 2.9520e-05 - val_mse: 3.6677e-05\n",
      "Epoch 125/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 3.5707e-05 - mse: 4.9311e-05 - val_loss: 3.7055e-05 - val_mse: 5.1979e-05\n",
      "Epoch 126/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 4.2340e-05 - mse: 6.2720e-05 - val_loss: 3.7808e-05 - val_mse: 5.3544e-05\n",
      "Epoch 127/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 3.6621e-05 - mse: 5.1391e-05 - val_loss: 3.4459e-05 - val_mse: 4.6978e-05\n",
      "Epoch 128/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 3.7060e-05 - mse: 5.2429e-05 - val_loss: 4.4640e-05 - val_mse: 6.7503e-05\n",
      "Epoch 129/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 4.1603e-05 - mse: 6.1593e-05 - val_loss: 3.6266e-05 - val_mse: 5.0802e-05\n",
      "Epoch 130/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 3.3904e-05 - mse: 4.6319e-05 - val_loss: 3.1176e-05 - val_mse: 4.0829e-05\n",
      "Epoch 131/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 3.8262e-05 - mse: 5.5215e-05 - val_loss: 4.0613e-05 - val_mse: 5.9831e-05\n",
      "Epoch 132/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 4.0753e-05 - mse: 6.0266e-05 - val_loss: 3.1628e-05 - val_mse: 4.1939e-05\n",
      "Epoch 133/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 3.3722e-05 - mse: 4.6306e-05 - val_loss: 2.7331e-05 - val_mse: 3.3514e-05\n",
      "Epoch 134/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 3.7522e-05 - mse: 5.4077e-05 - val_loss: 3.5805e-05 - val_mse: 5.0597e-05\n",
      "Epoch 135/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 4.0572e-05 - mse: 6.0199e-05 - val_loss: 2.7634e-05 - val_mse: 3.4296e-05\n",
      "Epoch 136/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 3.2757e-05 - mse: 4.4703e-05 - val_loss: 2.5943e-05 - val_mse: 3.1136e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 3.8477e-05 - mse: 5.6310e-05 - val_loss: 3.3905e-05 - val_mse: 4.7155e-05\n",
      "Epoch 138/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 3.8061e-05 - mse: 5.5523e-05 - val_loss: 2.5678e-05 - val_mse: 3.0778e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s_LSTM_256TimeD_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/500\n",
      "781/781 [==============================] - 17s 22ms/step - loss: 3.1630e-05 - mse: 4.2821e-05 - val_loss: 3.0104e-05 - val_mse: 3.9915e-05\n",
      "Epoch 140/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.9382e-05 - mse: 5.8467e-05 - val_loss: 3.8506e-05 - val_mse: 5.6782e-05\n",
      "Epoch 141/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.5412e-05 - mse: 5.0558e-05 - val_loss: 3.1595e-05 - val_mse: 4.3030e-05\n",
      "Epoch 142/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.2971e-05 - mse: 4.5848e-05 - val_loss: 5.6171e-05 - val_mse: 9.2473e-05\n",
      "Epoch 143/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.9041e-05 - mse: 5.8069e-05 - val_loss: 5.5482e-05 - val_mse: 9.1141e-05\n",
      "Epoch 144/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.2743e-05 - mse: 4.5610e-05 - val_loss: 6.3581e-05 - val_mse: 1.0752e-04\n",
      "Epoch 145/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.5907e-05 - mse: 5.2070e-05 - val_loss: 1.2579e-04 - val_mse: 2.3213e-04\n",
      "Epoch 146/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.6647e-05 - mse: 5.3610e-05 - val_loss: 9.3371e-05 - val_mse: 1.6734e-04\n",
      "Epoch 147/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.1185e-05 - mse: 4.2832e-05 - val_loss: 1.3394e-04 - val_mse: 2.4872e-04\n",
      "Epoch 148/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.7983e-05 - mse: 5.6525e-05 - val_loss: 1.9849e-04 - val_mse: 3.7794e-04\n",
      "Epoch 149/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.4135e-05 - mse: 4.8886e-05 - val_loss: 1.3397e-04 - val_mse: 2.4890e-04\n",
      "Epoch 150/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.1588e-05 - mse: 4.3953e-05 - val_loss: 2.6306e-04 - val_mse: 5.0734e-04\n",
      "Epoch 151/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.8618e-05 - mse: 5.8090e-05 - val_loss: 2.5645e-04 - val_mse: 4.9420e-04\n",
      "Epoch 152/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.1100e-05 - mse: 4.3129e-05 - val_loss: 1.6722e-04 - val_mse: 3.1577e-04\n",
      "Epoch 153/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.2380e-05 - mse: 4.5872e-05 - val_loss: 4.5326e-04 - val_mse: 8.8819e-04\n",
      "Epoch 154/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.7959e-05 - mse: 5.7069e-05 - val_loss: 2.5573e-04 - val_mse: 4.9308e-04\n",
      "Epoch 155/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 2.9236e-05 - mse: 3.9741e-05 - val_loss: 2.1458e-04 - val_mse: 4.1088e-04\n",
      "Epoch 156/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.3600e-05 - mse: 4.8612e-05 - val_loss: 5.0939e-04 - val_mse: 0.0010\n",
      "Epoch 157/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.6898e-05 - mse: 5.5222e-05 - val_loss: 2.1435e-04 - val_mse: 4.1055e-04\n",
      "Epoch 158/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 2.8211e-05 - mse: 3.7993e-05 - val_loss: 2.5097e-04 - val_mse: 4.8404e-04\n",
      "Epoch 159/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.5674e-05 - mse: 5.3036e-05 - val_loss: 4.3532e-04 - val_mse: 8.5294e-04\n",
      "Epoch 160/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.3199e-05 - mse: 4.8108e-05 - val_loss: 2.0674e-04 - val_mse: 3.9564e-04\n",
      "Epoch 161/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 2.8720e-05 - mse: 3.9308e-05 - val_loss: 3.1774e-04 - val_mse: 6.1794e-04\n",
      "Epoch 162/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.7260e-05 - mse: 5.6431e-05 - val_loss: 3.7662e-04 - val_mse: 7.3570e-04\n",
      "Epoch 163/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.0875e-05 - mse: 4.3703e-05 - val_loss: 1.8493e-04 - val_mse: 3.5227e-04\n",
      "Epoch 164/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 2.9545e-05 - mse: 4.1243e-05 - val_loss: 3.5268e-04 - val_mse: 6.8810e-04\n",
      "Epoch 165/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.6486e-05 - mse: 5.5153e-05 - val_loss: 3.1791e-04 - val_mse: 6.1857e-04\n",
      "Epoch 166/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 2.9025e-05 - mse: 4.0330e-05 - val_loss: 1.8363e-04 - val_mse: 3.4998e-04\n",
      "Epoch 167/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.0677e-05 - mse: 4.3778e-05 - val_loss: 3.9625e-04 - val_mse: 7.7549e-04\n",
      "Epoch 168/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.5592e-05 - mse: 5.3574e-05 - val_loss: 2.4814e-04 - val_mse: 4.7920e-04\n",
      "Epoch 169/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 2.7343e-05 - mse: 3.7209e-05 - val_loss: 2.1853e-04 - val_mse: 4.2010e-04\n",
      "Epoch 170/500\n",
      "781/781 [==============================] - 17s 21ms/step - loss: 3.3481e-05 - mse: 4.9585e-05 - val_loss: 4.1910e-04 - val_mse: 8.2147e-04\n",
      "CPU times: total: 1h 6s\n",
      "Wall time: 53min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec167337c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "#________________________________ LSTM\n",
    "\n",
    "name_model = \"s2s_LSTM_256TimeD_4\"\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Definir hiperparâmetros\n",
    "learning_rate = 0.0001\n",
    "l2_reg = 0.00001\n",
    "dropout_rate = 0.001\n",
    "func_act='sigmoid'\n",
    "\n",
    "batch_size = 128\n",
    "window_size = 32\n",
    "num_inputs  = train.shape[1]\n",
    "num_targets = 3\n",
    "stride = 3\n",
    "sampling_rate=1\n",
    "\n",
    "\n",
    "\n",
    "# Definir a entrada da rede\n",
    "inputs = keras.layers.Input(shape=[None, num_inputs])\n",
    "\n",
    "# LSTM\n",
    "reshaped_inputs = keras.layers.Reshape((-1, num_inputs))(inputs)\n",
    "lstm = keras.layers.LSTM(256, return_sequences=True, kernel_regularizer=keras.regularizers.L2(l2_reg))(reshaped_inputs)\n",
    "lstm = keras.layers.LSTM(256, return_sequences=True, kernel_regularizer=keras.regularizers.L2(l2_reg))(reshaped_inputs)\n",
    "lstm = keras.layers.Dropout(rate=dropout_rate)(lstm)\n",
    "lstm = keras.layers.LSTM(256, return_sequences=True, kernel_regularizer=keras.regularizers.L2(l2_reg))(lstm)\n",
    "lstm = keras.layers.LSTM(256, return_sequences=True, kernel_regularizer=keras.regularizers.L2(l2_reg))(reshaped_inputs)\n",
    "lstm = keras.layers.Dropout(rate=dropout_rate)(lstm)\n",
    "lstm = keras.layers.LSTM(256, return_sequences=True, kernel_regularizer=keras.regularizers.L2(l2_reg))(lstm)\n",
    "lstm = keras.layers.LSTM(256, return_sequences=True, kernel_regularizer=keras.regularizers.L2(l2_reg))(reshaped_inputs)\n",
    "lstm = keras.layers.Dropout(rate=dropout_rate)(lstm)\n",
    "\n",
    "# TimeDistributed Dense\n",
    "timed = keras.layers.TimeDistributed(keras.layers.Dense(256))(lstm)\n",
    "timed = keras.layers.TimeDistributed(keras.layers.Dropout(rate=dropout_rate))(timed)\n",
    "\n",
    "\n",
    "# LSTM\n",
    "lstm = keras.layers.LSTM(256, return_sequences=False, kernel_regularizer=keras.regularizers.L2(l2_reg))(timed)\n",
    "output_lstm = keras.layers.Dense(num_targets)(lstm)\n",
    "\n",
    "\n",
    "# Definir o modelo com a entrada e saída\n",
    "model = keras.models.Model(inputs=inputs, outputs=output_lstm)\n",
    "\n",
    "# Definir o otimizador com taxa de aprendizado definida\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "# Compilar o modelo com a função de perda, otimizador e métrica desejados\n",
    "model.compile(loss=keras.losses.logcosh, optimizer=optimizer, metrics=[\"mse\"])\n",
    "\n",
    "# Adicionar callbacks para o modelo\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(name_model, save_best_only=True)\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=32)\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(train_set,\n",
    "          steps_per_epoch= len(train)//batch_size,\n",
    "          epochs=500,\n",
    "          validation_data=valid_set,\n",
    "          validation_steps=len(valid)//batch_size,\n",
    "          callbacks=[early_stopping,\n",
    "                     model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a8db4e",
   "metadata": {},
   "source": [
    "# Avaliação e Ajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9eded3",
   "metadata": {},
   "source": [
    "A avaliação do modelo de previsão será realizado com a base reservada Teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd225236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s2s_LSTM_256TimeD_4'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08a9bfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 2s 11ms/step - loss: 9.3015e-05 - mse: 1.6915e-04\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(test_set, steps=len(test)//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3d4453",
   "metadata": {},
   "source": [
    "O treino salvou o melhor modelo encontrado. Iremos carregar esse modelo salvo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbfad016",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(name_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d392df",
   "metadata": {},
   "source": [
    "Testaremos o melhor modelo encontrado com os dados de Teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7e6097c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 3s 11ms/step - loss: 4.7651e-05 - mse: 7.4732e-05\n"
     ]
    }
   ],
   "source": [
    "loss, metric = model.evaluate(test_set, steps=len(test)//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13713143",
   "metadata": {},
   "source": [
    "# Previsões Futuras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbaeb8d",
   "metadata": {},
   "source": [
    "Realizaremos a previsões para nosso modelo em nossa base Teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3bf45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_set, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2bd383a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57872564, 0.5783797 , 0.5783342 ],\n",
       "       [0.578539  , 0.5782166 , 0.5782244 ],\n",
       "       [0.57888025, 0.578513  , 0.57854366],\n",
       "       [0.5776779 , 0.57730645, 0.57737327],\n",
       "       [0.5763285 , 0.5759784 , 0.57605183],\n",
       "       [0.57592726, 0.5755771 , 0.57563424],\n",
       "       [0.5766668 , 0.57632834, 0.5763514 ],\n",
       "       [0.57614326, 0.5758086 , 0.5758504 ],\n",
       "       [0.57657695, 0.57624245, 0.5762698 ],\n",
       "       [0.5759876 , 0.57563955, 0.57568955],\n",
       "       [0.57594895, 0.57562   , 0.57565653],\n",
       "       [0.57792807, 0.57764363, 0.5776154 ],\n",
       "       [0.5786599 , 0.5783142 , 0.5783211 ],\n",
       "       [0.5799767 , 0.57967424, 0.57965726],\n",
       "       [0.5810932 , 0.5807408 , 0.5807414 ],\n",
       "       [0.58138186, 0.58104897, 0.5810602 ],\n",
       "       [0.5804151 , 0.5800438 , 0.58010185],\n",
       "       [0.5802879 , 0.57993793, 0.5799794 ],\n",
       "       [0.5789787 , 0.5786108 , 0.5786827 ],\n",
       "       [0.5781096 , 0.5777306 , 0.5778055 ],\n",
       "       [0.5767593 , 0.5764286 , 0.5764975 ],\n",
       "       [0.5762976 , 0.5758908 , 0.5759705 ],\n",
       "       [0.57089084, 0.5704962 , 0.5706811 ],\n",
       "       [0.5707252 , 0.57040846, 0.57048243],\n",
       "       [0.56986076, 0.5695144 , 0.56958836],\n",
       "       [0.57200015, 0.57176065, 0.57172847],\n",
       "       [0.5742947 , 0.5739458 , 0.5739267 ],\n",
       "       [0.57263935, 0.57229626, 0.572357  ],\n",
       "       [0.5726381 , 0.57226354, 0.5723212 ],\n",
       "       [0.57085234, 0.5704946 , 0.5705799 ],\n",
       "       [0.569877  , 0.56946295, 0.56956154],\n",
       "       [0.566968  , 0.56661284, 0.5667334 ],\n",
       "       [0.5668179 , 0.5664903 , 0.56655353],\n",
       "       [0.567124  , 0.5667499 , 0.56680477],\n",
       "       [0.56408805, 0.5637422 , 0.5638583 ],\n",
       "       [0.5655438 , 0.56523085, 0.5652551 ],\n",
       "       [0.5655623 , 0.565189  , 0.56524026],\n",
       "       [0.56317645, 0.56280285, 0.5629129 ],\n",
       "       [0.563287  , 0.562973  , 0.56302214],\n",
       "       [0.5641305 , 0.56380355, 0.5638272 ],\n",
       "       [0.565865  , 0.56557393, 0.5655564 ],\n",
       "       [0.5650942 , 0.5646524 , 0.5647367 ],\n",
       "       [0.55567205, 0.55477643, 0.55523014],\n",
       "       [0.5094309 , 0.50845695, 0.5099102 ],\n",
       "       [0.49883896, 0.49862114, 0.49928355],\n",
       "       [0.4896375 , 0.48938632, 0.48986173],\n",
       "       [0.48413014, 0.4837328 , 0.4841379 ],\n",
       "       [0.4735834 , 0.47345248, 0.47384575],\n",
       "       [0.4726587 , 0.47250536, 0.4726859 ],\n",
       "       [0.47703612, 0.47688165, 0.4768422 ],\n",
       "       [0.4767655 , 0.47643384, 0.4764966 ],\n",
       "       [0.47678584, 0.47639695, 0.47648272],\n",
       "       [0.4752229 , 0.47488818, 0.4749849 ],\n",
       "       [0.4764108 , 0.47604954, 0.47609583],\n",
       "       [0.47763044, 0.47726056, 0.47728917],\n",
       "       [0.48011976, 0.47975126, 0.479742  ],\n",
       "       [0.48038578, 0.47996393, 0.48001587],\n",
       "       [0.47937912, 0.47895762, 0.4790565 ],\n",
       "       [0.48180038, 0.48143843, 0.48144385],\n",
       "       [0.48194927, 0.48156542, 0.48161152],\n",
       "       [0.48455834, 0.4841213 , 0.48413906],\n",
       "       [0.484145  , 0.48381108, 0.48384824],\n",
       "       [0.48661888, 0.4861779 , 0.48620287],\n",
       "       [0.4834137 , 0.48292115, 0.48308787],\n",
       "       [0.48091042, 0.48053938, 0.48068768],\n",
       "       [0.48419023, 0.48391256, 0.48388943],\n",
       "       [0.48629302, 0.4858534 , 0.4858744 ],\n",
       "       [0.48473805, 0.48431656, 0.48442078],\n",
       "       [0.48721075, 0.4869272 , 0.4869084 ],\n",
       "       [0.49135798, 0.49097034, 0.4909205 ],\n",
       "       [0.49169517, 0.49127206, 0.4913089 ],\n",
       "       [0.4934427 , 0.49307337, 0.49308005],\n",
       "       [0.49104923, 0.49055398, 0.49070314],\n",
       "       [0.49091   , 0.4905678 , 0.49064025],\n",
       "       [0.49348778, 0.49312574, 0.4931293 ],\n",
       "       [0.49487382, 0.4944758 , 0.49449864],\n",
       "       [0.4955595 , 0.49521527, 0.49523994],\n",
       "       [0.49549407, 0.49500343, 0.49510604],\n",
       "       [0.49706697, 0.496813  , 0.49679658],\n",
       "       [0.4972974 , 0.49677974, 0.49688005],\n",
       "       [0.49414778, 0.49372706, 0.4938853 ],\n",
       "       [0.49077308, 0.49034175, 0.49053985],\n",
       "       [0.49007595, 0.48973426, 0.48984578],\n",
       "       [0.4905554 , 0.49018198, 0.49025926],\n",
       "       [0.49116063, 0.490831  , 0.49087623],\n",
       "       [0.49313414, 0.49279523, 0.492804  ],\n",
       "       [0.49495137, 0.4945484 , 0.49456933],\n",
       "       [0.4916268 , 0.49117917, 0.49133888],\n",
       "       [0.49203038, 0.49167973, 0.49175268],\n",
       "       [0.4918722 , 0.49147198, 0.49155664],\n",
       "       [0.49165928, 0.49128613, 0.49136415],\n",
       "       [0.49265027, 0.4922503 , 0.4923086 ],\n",
       "       [0.4887427 , 0.48826945, 0.48846585],\n",
       "       [0.48587912, 0.48549202, 0.48566997],\n",
       "       [0.48548847, 0.48514518, 0.48524812],\n",
       "       [0.48775637, 0.48743662, 0.48744684],\n",
       "       [0.48952413, 0.48913512, 0.48915616],\n",
       "       [0.4891625 , 0.4887752 , 0.48884296],\n",
       "       [0.4882174 , 0.48781866, 0.4879193 ],\n",
       "       [0.48814726, 0.48772284, 0.4878187 ],\n",
       "       [0.4850725 , 0.48463312, 0.48480463],\n",
       "       [0.48361725, 0.48326388, 0.4833894 ],\n",
       "       [0.48580867, 0.48546126, 0.48548803],\n",
       "       [0.48247486, 0.4819966 , 0.4821781 ],\n",
       "       [0.48662627, 0.48644665, 0.48637122],\n",
       "       [0.48672342, 0.48614565, 0.48626104],\n",
       "       [0.48439753, 0.48399246, 0.48412418],\n",
       "       [0.47904718, 0.47860697, 0.47884893],\n",
       "       [0.47964615, 0.47938982, 0.4794512 ],\n",
       "       [0.4862678 , 0.48593822, 0.48583707],\n",
       "       [0.48470092, 0.48420724, 0.48430943],\n",
       "       [0.48407185, 0.48375103, 0.48381713],\n",
       "       [0.48528254, 0.4848396 , 0.48490623],\n",
       "       [0.48133093, 0.48085582, 0.4810493 ],\n",
       "       [0.4765867 , 0.47610593, 0.4763625 ],\n",
       "       [0.47433645, 0.4740465 , 0.47419092],\n",
       "       [0.47613543, 0.47569045, 0.4757758 ],\n",
       "       [0.47074008, 0.47035453, 0.4705629 ],\n",
       "       [0.47302318, 0.47275457, 0.47277823],\n",
       "       [0.47691816, 0.47654548, 0.47651306],\n",
       "       [0.4767064 , 0.47629395, 0.47634974],\n",
       "       [0.4754799 , 0.47505102, 0.47516242],\n",
       "       [0.47455925, 0.47415534, 0.4742631 ],\n",
       "       [0.47479624, 0.47440803, 0.47448233],\n",
       "       [0.47672212, 0.47636813, 0.47637942],\n",
       "       [0.47788572, 0.4774542 , 0.47749692],\n",
       "       [0.4760676 , 0.47563577, 0.47575477],\n",
       "       [0.47610462, 0.4757529 , 0.47582096]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87cdc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
